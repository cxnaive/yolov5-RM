Plotting labels...
[34m[1mautoanchor: [39m[22mAnalyzing anchors... anchors/target = 3.28, Best Possible Recall (BPR) = 1.0000
edit: torch.Size([56, 17])
tensor([[ 0.00000e+00,  4.00000e+00,  7.04424e-01,  7.81919e-01,  8.62585e-02,  6.65699e-02,  6.62271e-01,  7.48974e-01,  6.61309e-01,  7.90214e-01,  7.44389e-01,  8.14873e-01,  7.47544e-01,  7.64879e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 0.00000e+00,  5.00000e+00,  5.76143e-01,  6.46774e-01,  3.25915e-02,  2.77694e-02,  5.60357e-01,  6.33018e-01,  5.59850e-01,  6.54490e-01,  5.91106e-01,  6.60535e-01,  5.92436e-01,  6.37085e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 0.00000e+00,  4.00000e+00,  9.68677e-01,  7.96458e-01,  4.79749e-02,  8.65081e-02,  9.44717e-01,  7.94265e-01,  9.55998e-01,  8.39667e-01,  9.92642e-01,  7.91985e-01,  9.82908e-01,  7.53243e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.00000e+00,  1.00000e+00,  1.39658e-01,  1.40683e-01,  2.79316e-01,  1.69634e-01,  2.79081e-01,  1.16827e-01,  2.71178e-01,  2.25446e-01, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.00000e+00,  2.00000e+00,  9.31186e-01,  9.39820e-01,  6.05288e-02,  3.14642e-02,  9.61395e-01,  9.29482e-01,  9.56875e-01,  9.55522e-01,  9.00974e-01,  9.48356e-01,  9.05222e-01,  9.24117e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 2.00000e+00,  4.00000e+00,  5.07755e-02,  4.32496e-01,  4.57416e-02,  2.58155e-02,  2.79100e-02,  4.24502e-01,  2.95209e-02,  4.45391e-01,  7.36400e-02,  4.39696e-01,  7.17171e-02,  4.19602e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 2.00000e+00,  2.00000e+00,  8.65300e-01,  4.58343e-01,  3.57004e-02,  2.61197e-02,  8.47460e-01,  4.53946e-01,  8.48572e-01,  4.71395e-01,  8.83139e-01,  4.61146e-01,  8.82617e-01,  4.45287e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 2.00000e+00,  2.00000e+00,  7.49535e-01,  4.31586e-01,  1.76631e-02,  3.23200e-02,  7.44456e-01,  4.15531e-01,  7.40718e-01,  4.28023e-01,  7.53751e-01,  4.47648e-01,  7.58350e-01,  4.33094e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 2.00000e+00,  0.00000e+00,  7.84001e-01,  1.94630e-01,  2.09395e-02,  7.22132e-03,  7.73963e-01,  1.91174e-01,  7.73538e-01,  1.96906e-01,  7.93825e-01,  1.98087e-01,  7.94464e-01,  1.92397e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 2.00000e+00,  5.00000e+00,  1.84795e-01,  7.80271e-01,  4.87061e-02,  4.56051e-02,  1.60459e-01,  7.71869e-01,  1.67881e-01,  8.03018e-01,  2.09126e-01,  7.83780e-01,  2.03464e-01,  7.57511e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 2.00000e+00,  5.00000e+00,  2.10030e-02,  7.58817e-01,  3.47582e-02,  3.88529e-02,  7.68625e-03,  7.39622e-01,  3.65083e-03,  7.62549e-01,  3.37657e-02,  7.78016e-01,  3.83494e-02,  7.50100e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 2.00000e+00,  0.00000e+00,  7.41649e-01,  7.17736e-01,  4.32565e-02,  3.35792e-02,  7.20041e-01,  7.18904e-01,  7.23075e-01,  7.34503e-01,  7.63263e-01,  7.22241e-01,  7.58521e-01,  7.00983e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 3.00000e+00,  0.00000e+00,  5.11818e-01,  2.19563e-01,  2.73235e-01,  1.25923e-01,  6.33072e-01,  1.56711e-01,  6.48025e-01,  2.34856e-01,  3.92536e-01,  2.82400e-01,  3.75563e-01,  2.13578e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 3.00000e+00,  0.00000e+00,  4.57191e-01,  7.32688e-01,  1.72412e-01,  7.15372e-02,  5.35915e-01,  6.96973e-01,  5.43147e-01,  7.44553e-01,  3.78670e-01,  7.68402e-01,  3.71207e-01,  7.26188e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 4.00000e+00,  2.00000e+00,  3.24021e-01,  8.56240e-01,  3.52650e-02,  3.75812e-02,  3.36136e-01,  8.37469e-01,  3.41588e-01,  8.58935e-01,  3.11607e-01,  8.75012e-01,  3.06459e-01,  8.54704e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 4.00000e+00,  2.00000e+00,  1.81182e-01,  8.64735e-01,  4.41329e-02,  3.32944e-02,  2.03157e-01,  8.58847e-01,  2.00029e-01,  8.81380e-01,  1.59198e-01,  8.68477e-01,  1.62335e-01,  8.48090e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 5.00000e+00,  0.00000e+00,  7.42016e-01,  8.63140e-01,  5.15967e-01,  1.45388e-01,  4.95099e-01,  7.91876e-01,  4.84806e-01,  9.32862e-01, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 6.00000e+00,  2.00000e+00,  5.31701e-01,  4.55894e-01,  2.22604e-01,  1.23477e-01,  4.28522e-01,  3.95200e-01,  4.20697e-01,  4.81877e-01,  6.29243e-01,  5.16616e-01,  6.42697e-01,  4.27350e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 7.00000e+00,  2.00000e+00,  4.43175e-01,  5.16014e-01,  1.36563e-02,  7.58190e-03,  4.36378e-01,  5.12341e-01,  4.36389e-01,  5.17812e-01,  4.49781e-01,  5.19688e-01,  4.49960e-01,  5.14057e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 7.00000e+00,  2.00000e+00,  4.80474e-01,  5.05897e-01,  7.25012e-03,  1.22690e-02,  4.76904e-01,  5.07065e-01,  4.78669e-01,  5.12017e-01,  4.84040e-01,  5.04435e-01,  4.82741e-01,  4.99774e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 7.00000e+00,  8.00000e+00,  6.26537e-01,  4.61255e-01,  2.18046e-02,  1.04513e-02,  6.15670e-01,  4.60840e-01,  6.15840e-01,  4.66480e-01,  6.37402e-01,  4.61466e-01,  6.37151e-01,  4.56032e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 7.00000e+00,  8.00000e+00,  6.20948e-01,  4.03599e-01,  2.43558e-02,  9.08129e-03,  6.08800e-01,  4.03215e-01,  6.11027e-01,  4.08121e-01,  6.33092e-01,  4.03551e-01,  6.31169e-01,  3.99075e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 7.00000e+00,  1.00000e+00,  5.13113e-01,  4.50640e-01,  9.32999e-03,  1.51283e-02,  5.08527e-01,  4.53343e-01,  5.10046e-01,  4.58191e-01,  5.17699e-01,  4.47845e-01,  5.16227e-01,  4.43089e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 7.00000e+00,  3.00000e+00,  6.52013e-01,  4.28562e-01,  5.92299e-03,  1.02203e-02,  6.50430e-01,  4.23491e-01,  6.49081e-01,  4.27305e-01,  6.53217e-01,  4.33637e-01,  6.54941e-01,  4.29297e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 7.00000e+00,  1.00000e+00,  4.78685e-01,  4.66798e-01,  2.12317e-02,  7.84550e-03,  4.68069e-01,  4.63060e-01,  4.68277e-01,  4.68194e-01,  4.89090e-01,  4.70538e-01,  4.89260e-01,  4.65232e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 8.00000e+00,  2.00000e+00,  1.30142e-01,  7.72220e-03,  8.24676e-02,  1.54444e-02, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,  1.63253e-01,  1.50545e-02, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 8.00000e+00,  4.00000e+00,  4.46472e-01,  6.41367e-01,  1.17319e-01,  6.30831e-02,  3.92559e-01,  6.10416e-01,  3.87911e-01,  6.60374e-01,  4.99865e-01,  6.72321e-01,  5.05016e-01,  6.24546e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 9.00000e+00,  0.00000e+00,  5.82346e-01,  4.60352e-01,  2.67539e-01,  7.57462e-02,  7.15610e-01,  4.35698e-01,  7.11563e-01,  4.98212e-01,  4.49127e-01,  4.90525e-01,  4.52500e-01,  4.22491e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.00000e+01,  3.00000e+00,  3.49861e-01,  5.53311e-01,  4.88178e-02,  3.87184e-02,  3.25599e-01,  5.52872e-01,  3.33563e-01,  5.72608e-01,  3.74139e-01,  5.51790e-01,  3.68053e-01,  5.34000e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.00000e+01,  4.00000e+00,  6.22969e-01,  6.62194e-01,  5.43381e-02,  4.96749e-02,  5.95993e-01,  6.60924e-01,  5.97574e-01,  6.87018e-01,  6.49953e-01,  6.62428e-01,  6.49463e-01,  6.37362e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.00000e+01,  4.00000e+00,  4.83804e-01,  6.63012e-01,  3.52787e-02,  6.03732e-02,  4.70549e-01,  6.33063e-01,  4.66446e-01,  6.55216e-01,  4.96075e-01,  6.92968e-01,  5.01174e-01,  6.69385e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.10000e+01,  3.00000e+00,  1.18111e-01,  6.75860e-01,  8.84280e-02,  8.68653e-02,  1.62059e-01,  6.54321e-01,  1.50775e-01,  7.19261e-01,  7.41221e-02,  6.87292e-01,  8.40037e-02,  6.32454e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.10000e+01,  3.00000e+00,  4.32640e-01,  6.43430e-01,  1.17569e-01,  8.38876e-02,  4.80022e-01,  6.01772e-01,  4.91307e-01,  6.56838e-01,  3.86752e-01,  6.85092e-01,  3.73954e-01,  6.25446e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.20000e+01,  2.00000e+00,  5.67963e-01,  4.84521e-01,  3.13079e-02,  1.98310e-02,  5.52383e-01,  4.80112e-01,  5.54378e-01,  4.94327e-01,  5.83547e-01,  4.88008e-01,  5.82181e-01,  4.74718e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.20000e+01,  2.00000e+00,  4.75652e-01,  4.72329e-01,  1.76957e-02,  2.42614e-02,  4.69019e-01,  4.60206e-01,  4.66866e-01,  4.72420e-01,  4.82342e-01,  4.84452e-01,  4.84443e-01,  4.71181e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.20000e+01,  3.00000e+00,  4.40938e-01,  5.15679e-01,  3.22812e-02,  2.02187e-02,  4.24871e-01,  5.11725e-01,  4.26640e-01,  5.25674e-01,  4.57009e-01,  5.19123e-01,  4.55560e-01,  5.05685e-01, -1.00000e+00, -1.00000e+00,  2.00000e+00],
        [ 1.20000e+01,  3.00000e+00,  3.49922e-01,  5.01554e-01,  2.13738e-02,  2.38543e-02,  3.42369e-01,  4.89638e-01,  3.39293e-01,  5.02340e-01,  3.57285e-01,  5.13469e-01,  3.60552e-01,  5.00672e-01, -1.00000e+00, -1.00000e+00,  2.00000e+00],
        [ 1.30000e+01,  4.00000e+00,  5.77478e-01,  1.78276e-01,  6.18893e-02,  2.70505e-02,  5.47995e-01,  1.65198e-01,  5.46746e-01,  1.89902e-01,  6.07254e-01,  1.91353e-01,  6.08214e-01,  1.67235e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.30000e+01,  1.00000e+00,  2.96890e-01,  5.57837e-02,  8.01254e-02,  2.20879e-02,  2.56846e-01,  4.75065e-02,  2.59065e-01,  6.68125e-02,  3.36929e-01,  6.34568e-02,  3.35680e-01,  4.47478e-02, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.30000e+01,  4.00000e+00,  7.26519e-02,  1.56512e-01,  2.50385e-02,  2.79526e-02,  6.01708e-02,  1.47146e-01,  6.60622e-02,  1.70446e-01,  8.51407e-02,  1.66774e-01,  7.98400e-02,  1.42573e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.30000e+01,  4.00000e+00,  7.02521e-01,  1.72540e-01,  2.02985e-02,  2.78926e-02,  6.92396e-01,  1.61537e-01,  6.97301e-01,  1.86452e-01,  7.12620e-01,  1.80449e-01,  7.08340e-01,  1.58624e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.30000e+01,  1.00000e+00,  3.06605e-01,  7.99247e-01,  1.33263e-01,  3.24872e-02,  2.40000e-01,  7.87064e-01,  2.41175e-01,  8.15484e-01,  3.73211e-01,  8.11604e-01,  3.72715e-01,  7.83005e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.30000e+01,  5.00000e+00,  6.49513e-03,  6.66931e-01,  1.29903e-02,  2.37840e-02, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,  1.29590e-02,  6.74817e-01,  1.17002e-02,  6.55047e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.40000e+01,  1.00000e+00,  1.17231e-01,  3.77608e-01,  6.91540e-02,  4.91752e-02,  8.26867e-02,  3.86997e-01,  8.47734e-02,  4.01777e-01,  1.51777e-01,  3.67680e-01,  1.50981e-01,  3.53447e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.40000e+01,  1.00000e+00,  3.11419e-03,  3.23327e-01,  6.22838e-03,  6.10077e-02, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,  2.24158e-03,  3.53807e-01,  6.12566e-03,  3.39959e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.40000e+01,  3.00000e+00,  6.92940e-01,  3.28936e-01,  7.32427e-02,  4.42885e-02,  6.57052e-01,  3.06796e-01,  6.56344e-01,  3.39094e-01,  7.26828e-01,  3.51064e-01,  7.29540e-01,  3.17082e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.40000e+01,  4.00000e+00,  5.24400e-01,  2.43949e-01,  5.28120e-02,  3.39679e-02,  4.98039e-01,  2.40177e-01,  5.03605e-01,  2.60638e-01,  5.50761e-01,  2.47774e-01,  5.45081e-01,  2.27259e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.40000e+01,  3.00000e+00,  9.00402e-01,  3.02590e-01,  2.69416e-02,  5.76736e-02,  8.87000e-01,  2.99973e-01,  8.94775e-01,  3.31308e-01,  9.13815e-01,  3.00289e-01,  9.07820e-01,  2.73883e-01, -1.00000e+00, -1.00000e+00,  1.00000e+00],
        [ 1.40000e+01,  2.00000e+00,  1.16581e-01,  7.03461e-01,  4.69441e-02,  3.48231e-02,  9.48225e-02,  6.86060e-01,  9.31386e-02,  7.07160e-01,  1.37418e-01,  7.20857e-01,  1.40031e-01,  6.96586e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.40000e+01,  2.00000e+00,  2.62529e-01,  7.13648e-01,  1.70458e-02,  4.01428e-02,  2.54053e-01,  7.12272e-01,  2.57646e-01,  7.33636e-01,  2.71010e-01,  7.12626e-01,  2.66998e-01,  6.93658e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.40000e+01,  1.00000e+00,  3.32220e-01,  6.14981e-01,  2.64350e-02,  1.82808e-02,  3.22269e-01,  6.05861e-01,  3.19023e-01,  6.14527e-01,  3.40758e-01,  6.24093e-01,  3.45422e-01,  6.13383e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.40000e+01,  4.00000e+00,  2.69868e-01,  6.29766e-01,  1.15134e-02,  1.73762e-02,  2.64136e-01,  6.26954e-01,  2.66451e-01,  6.38397e-01,  2.75600e-01,  6.32488e-01,  2.72906e-01,  6.21133e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.40000e+01,  4.00000e+00,  8.26590e-01,  7.35299e-01,  6.11176e-02,  3.23120e-02,  7.96086e-01,  7.26092e-01,  7.99175e-01,  7.51093e-01,  8.57098e-01,  7.42769e-01,  8.53096e-01,  7.19499e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.50000e+01,  4.00000e+00,  8.04720e-01,  6.64445e-01,  5.18467e-02,  6.20408e-02,  8.24800e-01,  6.33453e-01,  8.30533e-01,  6.63803e-01,  7.84939e-01,  6.95437e-01,  7.78900e-01,  6.63145e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.50000e+01,  3.00000e+00,  9.93317e-01,  5.37418e-01,  1.33662e-02,  4.49020e-02, -1.00000e+00, -1.00000e+00, -1.00000e+00, -1.00000e+00,  9.86715e-01,  5.38345e-01,  9.93808e-01,  5.15131e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00],
        [ 1.50000e+01,  4.00000e+00,  6.14314e-01,  6.39086e-01,  6.02534e-02,  5.44307e-02,  6.44327e-01,  6.33687e-01,  6.39861e-01,  6.66030e-01,  5.84291e-01,  6.41791e-01,  5.89305e-01,  6.12140e-01, -1.00000e+00, -1.00000e+00,  0.00000e+00]], device='cuda:0')
nc!!!!!!: 9
tensor([0.13328, 0.02339, 0.06558, 0.12466, 0.25936, 0.60628], device='cuda:0')
edit: torch.Size([80, 17])
tensor([[ 0.00000,  1.00000,  0.65973,  ..., -1.00000, -1.00000,  1.00000],
        [ 0.00000,  1.00000,  0.74492,  ..., -1.00000, -1.00000,  1.00000],
        [ 1.00000,  1.00000,  0.09065,  ..., -1.00000, -1.00000,  0.00000],
        ...,
        [15.00000,  4.00000,  0.34451,  ..., -1.00000, -1.00000,  0.00000],
        [15.00000,  4.00000,  0.38072,  ..., -1.00000, -1.00000,  0.00000],
        [15.00000,  5.00000,  0.19632,  ..., -1.00000, -1.00000,  0.00000]], device='cuda:0')
Scanning '/home/cx/rmvision/datasets/final/train/labels.cache' for images and labels... 180 found, 0 missing, 0 empty, 0 corrupted: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 180/180 [00:00<?, ?it/s]
Scanning '/home/cx/rmvision/datasets/final/val/labels.cache' for images and labels... 20 found, 0 missing, 0 empty, 0 corrupted: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<?, ?it/s]
Images sizes do not match. This will causes images to be display incorrectly in the UI.
Image sizes 640 train, 640 test
Using 4 dataloader workers
Logging results to runs/train/exp20
Starting training for 250 epochs...
     Epoch   gpu_mem       box       obj       cls       col  landmark     total   targets  img_size
     0/249     2.42G    0.1333   0.02339   0.06558    0.1247    0.2594    0.6063        56       640:   8%|███████████▎                                                                                                                            | 1/12 [00:02<00:22,  2.06s/it]/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [64,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [65,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [4,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [5,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [40,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [41,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [110,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [111,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [1,0,0], thread: [22,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [1,0,0], thread: [23,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && "index out of bounds"` failed.
THCudaCheck FAIL file=/opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/THC/THCCachingHostAllocator.cpp line=280 error=710 : device-side assert triggered
     0/249     2.42G    0.1333   0.02339   0.06558    0.1247    0.2594    0.6063        56       640:   8%|███████████▎                                                                                                                            | 1/12 [00:02<00:23,  2.12s/it]
Traceback (most recent call last):
  File "train.py", line 513, in <module>
    train(hyp, opt, device, tb_writer, wandb)
  File "train.py", line 290, in train
    loss, loss_items = compute_loss(pred, targets.to(device), model)  # loss scaled by batch_size
  File "/home/cx/rmvision/yolov5-face/utils/loss.py", line 119, in compute_loss
    tcls, tbox, indices, anchors, tlandmarks, lmks_mask, tcol = build_targets(p, targets, model)  # targets
  File "/home/cx/rmvision/yolov5-face/utils/loss.py", line 273, in build_targets
    lks[:, [0, 1]] = (lks[:, [0, 1]] - gij)
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.